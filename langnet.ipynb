{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "langnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO04CAUccW6y+wnZU90UPvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavela/Linguistics-with-conllu-data/blob/master/langnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5At7UsUiioJN"
      },
      "source": [
        "# Using dependency parses for analyzing language\n",
        "\n",
        "Focus here on ready-made Python scripts\n",
        "* (Although some of the first commands are in [Bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)))\n",
        "* All the scripts are downloadable at https://github.com/mavela/Linguistics-with-conllu-data.git (disclaimer for code beauty!)\n",
        "* You can also use tagged data with corpus tools, such as Antconc\n",
        "** See https://www.youtube.com/watch?v=gkKna-ka9zw\n",
        "\n",
        "\n",
        "The examples follow the distinction of two research designs in corpus linguistics ([see Biber & Jones 2009](https://jan.ucc.nau.edu/biber/Biber/Biber_offprint.pdf)) \n",
        "*   Type A focuses on individual forms (words, lemmas, constructions)\n",
        "*   Type B focuses on entire texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63O02lOfw-mt"
      },
      "source": [
        "## Preparations\n",
        "\n",
        "Let's download the data from Github!\n",
        "* cd takes us to the correct directory\n",
        "* ! ls lists the files in that directory\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO-_J2sa8tMW",
        "outputId": "d266a961-13df-4d43-92e8-9578df647d14"
      },
      "source": [
        "! git clone https://github.com/mavela/Linguistics-with-conllu-data.git\n",
        "% cd Linguistics-with-conllu-data\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Linguistics-with-conllu-data'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 34 (delta 15), reused 27 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n",
            "/content/Linguistics-with-conllu-data\n",
            "analyze.py\t  narrative_ext.conllu\t\t  pb_smallpart.conllu.gz\n",
            "how-to.conllu.gz  pb_even_smaller_part.conllu.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-TpGYLJ4qq"
      },
      "source": [
        "### Checking the basics\n",
        "! zcat prints the file the entire file, head -20 cuts after 20 first lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv6vB5mjJ3uO",
        "outputId": "249fdd6d-34e9-47fc-cf0d-15c043de7dc2"
      },
      "source": [
        "! zcat pb_smallpart.conllu.gz | head -20 # How the data look like"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# <doc id=\"7-510353\" length=\"0-1k\" crawl_date=\"2015-06-05\" url=\"http://yle.fi/uutiset/lahden_paikallisliikenteen_uudistus_edennyt_ilman_suuria_ongelmia/7338226?origin=rss\" langdiff=\"0.11\">\n",
            "# delex_lm_mean_perplexity: 210.51\n",
            "# lex_lm_mean_perplexity: 32064.49\n",
            "# predicted register: narrative\n",
            "# <p heading=\"0\">\n",
            "# paragraph_delex_lm_mean_perplexity: 368.98\n",
            "# paragraph_lexical_lm_mean_perplexity: 50604.32\n",
            "# text = Suurilta ja toistuvilta myöhästymisiltä tai muilta kommelluksilta on vältytty.\n",
            "# </p>\n",
            "1\tSuurilta\tsuuri\tADJ\t_\tCase=Abl|Degree=Pos|Number=Plur\t4\tamod\t_\t_\n",
            "2\tja\tja\tCCONJ\t_\t_\t3\tcc\t_\t_\n",
            "3\ttoistuvilta\ttoistuva\tADJ\t_\tCase=Abl|Degree=Pos|Number=Plur\t1\tconj\t_\t_\n",
            "4\tmyöhästymisiltä\tmyöhästyminen\tNOUN\t_\tCase=Nom|Derivation=Minen|Number=Plur\t9\tobl\t_\t_\n",
            "5\ttai\ttai\tCCONJ\t_\t_\t7\tcc\t_\t_\n",
            "6\tmuilta\tmuu\tPRON\t_\tCase=Abl|Number=Sing|PronType=Dem\t7\tdet\t_\t_\n",
            "7\tkommelluksilta\tkommellus\tNOUN\t_\tCase=Abl|Number=Plur\t4\tconj\t_\t_\n",
            "8\ton\tolla\tAUX\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\t9\taux:pass\t_\t_\n",
            "9\tvältytty\tvälttyä\tVERB\t_\tCase=Nom|Degree=Pos|Number=Sing|PartForm=Past|VerbForm=Part|Voice=Pass\t0\troot\t_\t_\n",
            "10\t.\t.\tPUNCT\t_\t_\t9\tpunct\t_\t_\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODW0qMMMW4nS"
      },
      "source": [
        "## Word counts\n",
        "Note that we have to skip empty lines and metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyTaNQFBKnyN",
        "outputId": "eafa7879-e817-4ecb-8c5f-5b093f75c622"
      },
      "source": [
        "from analyze import count_words, most_frequent, extract_register, print_text\n",
        "\n",
        "print(\"Total word count of the conllu file is\", count_words(\"pb_smallpart.conllu.gz\"), \"tokens\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total word count of the conllu file is 6004519 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Szn6TGxim_"
      },
      "source": [
        "## Lemmatization\n",
        "\n",
        "One of the most frequent uses of the parser is simply lemmatization.\n",
        "\n",
        "print_text prints one text per line the text featurized as we indicate.\n",
        "\n",
        "We can specify the kind of feature by referring to the column name in the Conll format.\n",
        "\n",
        "The columns are: \n",
        "* ID, FORM, LEMMA, UPOS, XPOS, FEAT, HEAD, DEPREL, DEPS, MISC \n",
        "\n",
        "The number indicates how many texts we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG6LkPlhxsFt",
        "outputId": "90ca12c4-d943-4c51-90a4-fa8b019c9567"
      },
      "source": [
        "print(print_text(\"pb_smallpart.conllu.gz\", \"FORM\", 2))\n",
        "print()\n",
        "print(print_text(\"pb_smallpart.conllu.gz\", \"LEMMA\", 2))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Suurilta ja toistuvilta myöhästymisiltä tai muilta kommelluksilta on vältytty . – Tietooni ei ole tullut liikennöitsijöiltä sellaisia linjoja , joissa toistuvia myöhästelyjä olisi . Kuljettajatkin ovat olleet tyytyväisiä uusin reitteihin , vaikka varmasti paljon uutta on ollut omaksuttavana . Myöhästelyt ovat Jorasmaan mukaan johtuneet lähes poikkeuksetta lipunmyyntijärjestelmän ongelmista .\n",
            "\n",
            "Translate sunnuntai 2. joulukuuta 2012 Poronkäristys Aivan loistava ruoka näin tuulen tuivertaessa lunta ikkunoihin . On hanget korkeat nietokset ( ainakin toivottavasti muutaman päivän ) ja pihalta tullessa tuhti ruoka lämmittää sopivasti . Poro on lihana miedonmakuinen ja vähärasvainen joten se on hyvää vaihtelua naudan- ja possunlihalle . Saimme 10kg poroa tuoreena suoraan lapista setäni kautta ja tänä talvena pääsemme kokeilemaan tästä pohjoisen herkusta moninaisia ruokia . Paistia on jo tullut testattua ja käristystäkin kerran . Teimme ensimmäisen kerran käristyksen \" ainoan ja oikean \" ohjeen mukaan jossa käristykseen ei tule kuin suolaa ja pippuria mausteeksi ja vettä nesteeksi . Halusin kuitenkin syventää makua ja kokeilla jotain uutta . Hain inspiraatiota netin tarjonnasta ja törmäsin yhdessä suosikkiblogeistani tähän ohjeeseen . Nesteenä siinä on lihaliemen ohella tummaa olutta . Itse en to-del-la-kaan ole oluen ystävä . Pelkkä kaljan hajukin on saanut voimaan pahoin ( mistä lie johtuu ? ) mutta rohkaistuin ostamaan Alkosta tähän ruokaan tsekkiläistä tummaa olutta . Pullossa seisoo nimi Kozel ja täytyy kyllä sanoa , että sopi tähän ruokaan todella hyvin . Olut ei haissut edes pahalla :) Tuskin minusta oluen ystävää saa silti tehtyä mutta tätä tulee kyllä jatkossa varmasti lorautettua käristyksen joukkoon . Ohjeesta poiketen en laittanut koko pulloa vaan tyydyin puolikkaaseen . Nesteen määrä ruuassa on muutenkin arvioitava silmämääräisesti . Tuoreita yrttejä ei ollut tällä kertaa saatavilla ja muutenkin tuunailin ohjetta määrien osalta lennosta , mutta ohjeesta saa suuntaviivat mihin pitäisi pyrkiä . Ja kerrotaan nyt tässä vaiheessa , että olihan hyvää ! Tumma , hyvin maustunut ja mehukas käristys maistui myös lapsille . Tätä tehdään uudelleen .\n",
            "\n",
            "suuri ja toistuva myöhästyminen tai muu kommellus olla välttyä . – tieto ei olla tulla liikennöitsijä sellainen linja , joka toistuva myöhästely olla . kuljettaja olla olla tyytyväinen uusi reitti , vaikka varmasti paljon uusi olla olla omaksua . myöhästelyn olla Jorasmaa mukaan johtua lähes poikkeuksetta lipun#myynti#järjestelmä ongelma .\n",
            "\n",
            "translate sunnuntai 2. joulukuu 2012 poron#käristys aivan loistava ruoka näin tuuli tuivertaa lumi ikkuna . olla hanki korkea nietos ( ainakin toivottavasti muutama päivä ) ja piha tulla tuhti ruoka lämmittää sopivasti . poro olla liha miedon#makuinen ja vähä#rasvainen joten se olla hyvä vaihtelu naudan ja possun#liha . saada 10kg poro tuore suoraan lappi setä kautta ja tämä talvi päästä kokeilla tämä pohjoinen herkku moninainen ruoka . paisti olla jo tulla testata ja käristys#täki kerran . tehdä ensimmäinen kerran käristys \" ainoa ja oikea \" ohje mukaan joka käristys ei tulla kuin suola ja pippuri mauste ja vesi neste . haluta kuitenkin syventää maku ja kokeilla jokin uusi . hakea inspiraatio netti tarjonta ja törmätä yksi suosikki#blogi tämä ohje . neste se olla liha#liemi ohella tumma olut . itse ei to-del-la-kaan olla olut ystävä . pelkkä kalja haju olla saada voida pahoin ( mikä lie johtua ? ) mutta rohkaistua ostaa Alko tämä ruoka tsekkiläinen tumma olut . pullo seisoa nimi Kozel ja täytyä kyllä sanoa , että sopia tämä ruoka todella hyvin . olut ei haista edes pahalla :) tuskin minä olut ystävä saada silti tehdä mutta tämä tulla kyllä jatko varmasti lorauttaa käristys joukko . ohje poiketa ei laittaa koko pullo vaan tyytyä puolikas . neste määrä ruoka olla muuten arvioida silmä#määräisesti . tuore yrtti ei olla tämä kerta saada ja muuten tuunailla ohje määrä osa lento , mutta ohje saada suunta#viiva mikä pitää pyrkiä . ja kertoa nyt tämä vaihe , että oliha hyvä ! tumma , hyvin maustua ja mehukas käristys maistua myös lapsi . tämä tehdä uudelleen .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM3YjHGw7VUd"
      },
      "source": [
        "## Type A perspective: Analyzing / searching for individual words / lemmas\n",
        "\n",
        "How many times a particular lemma appears in the corpus?\n",
        "\n",
        "What are its most frequent dependency relations? (Or other tags)\n",
        "\n",
        "The Conllu tagsets (columns) are defined as: ID,FORM,LEMMA,UPOS,XPOS,FEAT,HEAD,DEPREL,DEPS,MISC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjyKvTjU1dEM",
        "outputId": "4ade3b15-ac34-4dd2-909f-7ee2ad806254"
      },
      "source": [
        "from analyze import count_specific_lemma, count_word_context\n",
        "\n",
        "#NOTE THESE ARE LEMMAS WE ARE SEARCHING FOR\n",
        "print(count_specific_lemma(\"koira\", \"pb_smallpart.conllu.gz\", \"FORM\"))\n",
        "print(count_specific_lemma(\"koira\", \"pb_smallpart.conllu.gz\", \"DEPREL\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total counts for the lemma koira: 563\n",
            "The most frequent  FORM:\n",
            "koira 149\n",
            "koiran 68\n",
            "koiraa 49\n",
            "koiria 48\n",
            "koirat 47\n",
            "Koira 31\n",
            "koirien 29\n",
            "Koirat 16\n",
            "Koiran 13\n",
            "koirilla 13\n",
            "koiransa 11\n",
            "koiralle 9\n",
            "koirille 9\n",
            "koirasta 7\n",
            "koirista 7\n",
            "\n",
            "Total counts for the lemma koira: 563\n",
            "The most frequent  DEPREL:\n",
            "nsubj 94\n",
            "obj 83\n",
            "obl 68\n",
            "conj 59\n",
            "nmod 54\n",
            "root 53\n",
            "nmod:poss 52\n",
            "nsubj:cop 40\n",
            "compound:nn 17\n",
            "appos 14\n",
            "advcl 8\n",
            "nmod:gobj 5\n",
            "ccomp 4\n",
            "nmod:gsubj 3\n",
            "flat:name 3\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rZX14_d2rfK"
      },
      "source": [
        "## Surrounding words or other context\n",
        "\n",
        "What kinds of words is the target word collocating with?\n",
        "(Note that this is just a frequency list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6IsZDxK2rAi",
        "outputId": "8f80ecab-208d-41e8-f4dc-a029e0f62fc2"
      },
      "source": [
        "print(count_word_context(\"koira\", \"LEMMA\", \"pb_smallpart.conllu.gz\"))\n",
        "print()\n",
        "print(count_word_context(\"koira\", \"UPOS\", \"pb_smallpart.conllu.gz\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "koira 105\n",
            "olla 46\n",
            "ja 43\n",
            "se 18\n",
            "hän 16\n",
            "joka 12\n",
            "kun 8\n",
            "ei 6\n",
            "tulla 5\n",
            "voida 5\n",
            "mutta 5\n",
            "että 5\n",
            "tehdä 5\n",
            "tämä 5\n",
            "minä 4\n",
            "jos 4\n",
            "tai 4\n",
            "lapsi 4\n",
            "oma 4\n",
            "tuo 4\n",
            "\n",
            "\n",
            "NOUN 337\n",
            "VERB 125\n",
            "PROPN 70\n",
            "PRON 67\n",
            "ADV 66\n",
            "ADJ 64\n",
            "CCONJ 56\n",
            "AUX 51\n",
            "SCONJ 23\n",
            "NUM 11\n",
            "ADP 10\n",
            "SYM 6\n",
            "INTJ 2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAkxw-vqf3Eh"
      },
      "source": [
        "## Type B perspective: Text level\n",
        "### Most frequent tokens + lemmas in a text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFz9Go4pGi7o",
        "outputId": "5a612eda-413e-4dd3-8dc4-42162450e757"
      },
      "source": [
        "print(\"Most frequent tokens\")\n",
        "print(most_frequent(\"pb_smallpart.conllu.gz\", \"FORM\", 10)) # the number defines how many we want to see\n",
        "\n",
        "print(\"Most frequent lemmas\")\n",
        "print(most_frequent(\"pb_smallpart.conllu.gz\", \"LEMMA\", 10)) # the number defines how many we want to see"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most frequent tokens\n",
            "ja 187895\n",
            "on 98379\n",
            "oli 49492\n",
            "että 37319\n",
            "ei 29839\n",
            "joka 24799\n",
            "hän 23282\n",
            "vuonna 20998\n",
            "hänen 19782\n",
            "se 18595\n",
            "\n",
            "Most frequent lemmas\n",
            "olla 224316\n",
            "ja 190309\n",
            "hän 80894\n",
            "se 75515\n",
            "joka 58328\n",
            "vuosi 47916\n",
            "ei 47496\n",
            "että 37784\n",
            "tämä 35210\n",
            "kun 21057\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFJsqr1jXtw8"
      },
      "source": [
        "## Distribution of POS tags or dependency relations\n",
        "The Conllu tagsets (columns) are defined as:\n",
        "ID,FORM,LEMMA,UPOS,XPOS,FEAT,HEAD,DEPREL,DEPS,MISC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzlnGRm4M7no",
        "outputId": "90803717-9ed5-4d71-dd45-b975252d9a7d"
      },
      "source": [
        "print(\"Most frequent lemmas, or whatever tagset (column) is specified\")\n",
        "print(most_frequent(\"pb_smallpart.conllu.gz\", \"LEMMA\", 10))\n",
        "\n",
        "print(\"Then the most frequent part-of-speech tags\")\n",
        "print(most_frequent(\"pb_smallpart.conllu.gz\", \"UPOS\", 10))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most frequent lemmas, or whatever tagset (column) is specified\n",
            "olla 224316\n",
            "ja 190309\n",
            "hän 80894\n",
            "se 75515\n",
            "joka 58328\n",
            "vuosi 47916\n",
            "ei 47496\n",
            "että 37784\n",
            "tämä 35210\n",
            "kun 21057\n",
            "\n",
            "Then the most frequent part-of-speech tags\n",
            "NOUN 1557042\n",
            "PROPN 808304\n",
            "VERB 654108\n",
            "ADJ 381399\n",
            "ADV 381011\n",
            "PRON 362355\n",
            "AUX 287354\n",
            "CCONJ 246675\n",
            "NUM 195055\n",
            "SCONJ 105037\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLXMxQ7JHZFc"
      },
      "source": [
        "## Focusing text-level analysis to particular tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt_Ku3mkHa0J",
        "outputId": "196633d5-3327-4266-df4d-f29374a725c8"
      },
      "source": [
        "print(\"Most frequent lemmas under a specific tagset(column).\")\n",
        "print(\"For instance, the most frequent lemmas that receive the ADJ tag in the UPOS column.\")\n",
        "print()\n",
        "print(most_frequent(\"pb_smallpart.conllu.gz\", \"UPOS\", 10, \"ADJ\"))\n",
        "\n",
        "print(\"Or the most frequent lemmas that receive nsubj that in the DEPREL column\")\n",
        "print()\n",
        "print(most_frequent(\"pb_smallpart.conllu.gz\", \"DEPREL\", 10, \"nsubj\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most frequent lemmas under a specific tagset(column).\n",
            "For instance, the most frequent lemmas that receive the ADJ tag in the UPOS column.\n",
            "\n",
            "ensimmäinen 11915\n",
            "suuri 9877\n",
            "hyvä 8696\n",
            "uusi 8267\n",
            "usea 6615\n",
            "oma 6224\n",
            "toinen 6027\n",
            "pieni 4724\n",
            "koko 3994\n",
            "eri 3896\n",
            "\n",
            "Or the most frequent lemmas that receive nsubj that in the DEPREL column\n",
            "\n",
            "hän 35406\n",
            "joka 21604\n",
            "se 14226\n",
            "tämä 2813\n",
            "minä 2734\n",
            "mikä 2110\n",
            "ihminen 1571\n",
            "joku 1183\n",
            "hallitus 1109\n",
            "osa 1083\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZazPEyjFcuC"
      },
      "source": [
        "## Focus and / or compare specific registers\n",
        "\n",
        "Registers used:\n",
        "* how-to/instructions\n",
        "* informational description\n",
        "* informational persuasion general\n",
        "* interactive discussion\n",
        "* machine translated\n",
        "* narrative\n",
        "* opinion\n",
        "\n",
        "The Github repo includes two register-specific datasets: narrative and how-to/instructions. You can also extract other registers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6kRIX2_8L1J",
        "outputId": "ece75745-e320-4231-9bcd-9d23a6136bd3"
      },
      "source": [
        "from analyze import extract_register\n",
        "\n",
        "extract_register(\"opinion\", \"pb_smallpart.conllu.gz\")\n",
        "\n",
        "! ls # see it's there!"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote opinion texts to a file!\n",
            "analyze.py\t      opinion_ext.conllu\t      __pycache__\n",
            "how-to.conllu.gz      pb_even_smaller_part.conllu.gz\n",
            "narrative_ext.conllu  pb_smallpart.conllu.gz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}